{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e9e7a5",
   "metadata": {},
   "source": [
    "<h1>I had tried to make a traffic sign classification Neural Network model using CNN. The data set which has been used in this deep learning model is GTSRB - German Traffic Sign Recognition Benchmark dataset.\n",
    "It contains the traffic sign images classified in different and separate folders.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe24e37c",
   "metadata": {},
   "source": [
    "<h2>Importing the required modules</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15aec312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b844c",
   "metadata": {},
   "source": [
    "<h2>Data understanding and clearing \n",
    "by giving the labels</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547eddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43 \n",
    "cur_path = os.getcwd() \n",
    "for i in range(classes): \n",
    "  path = os. path.join(cur_path,'Train', str(i)) \n",
    "  images = os.listdir(path) \n",
    "  for a in images: \n",
    "    try: \n",
    "        image = Image.open(path +\"/\"+ a) \n",
    "        image = image.resize((30,30)) \n",
    "        image = np.array(image) \n",
    "        data.append(image) \n",
    "        labels.append(i) \n",
    "    except: \n",
    "        print(\"Error loading image\") \n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8fcef",
   "metadata": {},
   "source": [
    "<h2>so we get that our data contain total 39209 images of 30x30</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804b853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83f247",
   "metadata": {},
   "source": [
    "<h2>Now we separate the total images into train and test dataset. Using the train_test_split function we split the dataset\n",
    ",thus the 80% of data is stored for training and 20% for the test dataset.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd763ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31367, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "X_t1,X_t2,y_t1,y_t2=train_test_split(data,labels,test_size=0.2 ,random_state=42)\n",
    "print(X_t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c865d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 20:54:41.521186: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 20:54:55.980459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-21 20:54:55.980583: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-21 20:54:57.109971: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-21 20:55:27.769432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-21 20:55:27.769975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-21 20:55:27.770015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_t1=to_categorical(y_t1,43)\n",
    "y_t2=to_categorical(y_t2,43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f15d77",
   "metadata": {},
   "source": [
    "<h2>Now we come to most important part is to make the cnn model, thus we have used sequential for the model. I had made layers of conv2d and maxpooling using relu activation.\n",
    "In the end of neural network i had used dense layer by softmax activation thus it can be helpfull to separate the data as per the label</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891c8b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 20:57:24.189749: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-21 20:57:24.321431: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-21 20:57:24.392122: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vicky-dev): /proc/driver/nvidia/version does not exist\n",
      "2022-11-21 20:57:24.853766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Dropout,Conv2D,MaxPooling2D\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(6,6),activation='relu',input_shape=(30,30,3)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(43,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c2061",
   "metadata": {},
   "source": [
    "<h2>fiting the model by using the epochs of 12 and 32 batchsize</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba273c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "981/981 [==============================] - 184s 187ms/step - loss: 0.2522 - accuracy: 0.9362 - val_loss: 0.0808 - val_accuracy: 0.9810\n",
      "Epoch 2/15\n",
      "981/981 [==============================] - 179s 182ms/step - loss: 0.1630 - accuracy: 0.9605 - val_loss: 0.1015 - val_accuracy: 0.9776\n",
      "Epoch 3/15\n",
      "981/981 [==============================] - 147s 150ms/step - loss: 0.1391 - accuracy: 0.9660 - val_loss: 0.1066 - val_accuracy: 0.9764\n",
      "Epoch 4/15\n",
      "981/981 [==============================] - 139s 142ms/step - loss: 0.1226 - accuracy: 0.9710 - val_loss: 0.0724 - val_accuracy: 0.9853\n",
      "Epoch 5/15\n",
      "981/981 [==============================] - 131s 134ms/step - loss: 0.1124 - accuracy: 0.9730 - val_loss: 0.0646 - val_accuracy: 0.9874\n",
      "Epoch 6/15\n",
      "981/981 [==============================] - 133s 136ms/step - loss: 0.1119 - accuracy: 0.9756 - val_loss: 0.1309 - val_accuracy: 0.9793\n",
      "Epoch 7/15\n",
      "981/981 [==============================] - 133s 136ms/step - loss: 0.1107 - accuracy: 0.9777 - val_loss: 0.0579 - val_accuracy: 0.9906\n",
      "Epoch 8/15\n",
      "981/981 [==============================] - 134s 136ms/step - loss: 0.0830 - accuracy: 0.9816 - val_loss: 0.1227 - val_accuracy: 0.9783\n",
      "Epoch 9/15\n",
      "981/981 [==============================] - 133s 135ms/step - loss: 0.1536 - accuracy: 0.9733 - val_loss: 0.0591 - val_accuracy: 0.9907\n",
      "Epoch 10/15\n",
      "981/981 [==============================] - 133s 136ms/step - loss: 0.0802 - accuracy: 0.9834 - val_loss: 0.0536 - val_accuracy: 0.9916\n",
      "Epoch 11/15\n",
      "981/981 [==============================] - 134s 136ms/step - loss: 0.0942 - accuracy: 0.9835 - val_loss: 0.0791 - val_accuracy: 0.9888\n",
      "Epoch 12/15\n",
      "981/981 [==============================] - 134s 137ms/step - loss: 0.1066 - accuracy: 0.9817 - val_loss: 0.1046 - val_accuracy: 0.9866\n",
      "Epoch 13/15\n",
      "981/981 [==============================] - 134s 137ms/step - loss: 0.1336 - accuracy: 0.9800 - val_loss: 0.1206 - val_accuracy: 0.9897\n",
      "Epoch 14/15\n",
      "981/981 [==============================] - 133s 136ms/step - loss: 0.0840 - accuracy: 0.9860 - val_loss: 0.0741 - val_accuracy: 0.9911\n",
      "Epoch 15/15\n",
      "981/981 [==============================] - 134s 137ms/step - loss: 0.0950 - accuracy: 0.9851 - val_loss: 0.1131 - val_accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_t1,y_t1,batch_size=32,epochs=15, validation_data=(X_t2,y_t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45bee2",
   "metadata": {},
   "source": [
    "<h2>After training of the model we get the accuracy of 98%. so the model seems to work good and able to detect the sign board, lets try it on test dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 21:00:34.755451: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34101000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 24s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy on test dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('Test.csv')\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = y_test[\"Path\"].values\n",
    "data=[]\n",
    "for img in imgs:\n",
    "   image = Image.open(img)\n",
    "   image = image.resize((30,30))\n",
    "   data.append(np.array(image))\n",
    "X_test=np.array(data)\n",
    "y_predict = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b74d9d",
   "metadata": {},
   "source": [
    "<h2>Accuracy of model</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1172cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b19448",
   "metadata": {},
   "source": [
    "<h2>Saving the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "559a8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Traffic_sgin_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fac4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
